{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EMBO Practical Course \"Advanced methods in bioimage analysis\"\n",
    "\n",
    "***\n",
    "\n",
    "Homepage: https://www.embl.org/about/info/course-and-conference-office/events/bia23-01/\n",
    "\n",
    "***\n",
    "\n",
    "## Day 2 - Session 1: Image Data Management - 11:30 to 12:30 \"GO!\"\n",
    "\n",
    "<table style=\"table { position: relative;  display: inline-block; } img {  position: absolute;  left: 0;  right: 0;  width: auto;  height: 100%;  object-fit: cover;  object-position: center;}\">\n",
    "    <tr>\n",
    "        <td style=\"vertical-align: top\">\n",
    "            <h3>Introduction</h3>\n",
    "            <p>\n",
    "                In this notebook, we'll switch from looking at the filesystem to looking at the cloud.\n",
    "                \"S3\" and other object storage backends get rid of many of the POSIX constraints, leaving\n",
    "                many tools unable to (⚠ Caveat: without something like the mounting tool). After looking\n",
    "                differences and the available tools, we'll see how to migrate to OME-Zarr and what that\n",
    "                gives you access to.\n",
    "            </p>\n",
    "            <p>\n",
    "                Outline:\n",
    "                <ol start=\"5\">\n",
    "                    <li>The Cloud\n",
    "                        <ol type=\"a\">\n",
    "                            <li>S3</li>\n",
    "                            <li>aws &amp; s3</li>\n",
    "                            <li>Our bucket</li>\n",
    "                            <li>Extras: time permitting\n",
    "                            </li>\n",
    "                        </ol>\n",
    "                    </li>\n",
    "                        <li>OME-Zarr\n",
    "                        <ol type=\"a\">\n",
    "                            <li>Generating OME-Zarrs</li>\n",
    "                            <li>Publishing OME-Zarrs</li>\n",
    "                            <li>Looking deeper into OME-Zarrs</li>\n",
    "                            <li>Other options</li>\n",
    "                        </ol>\n",
    "                    </li>\n",
    "                </ol>\n",
    "            </p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <center>\n",
    "                <img src=\"images/falk/adam-uploads-300dpi.png\"/>\n",
    "                <small>\n",
    "                    <a href=\"https://github.com/zarr-developers/zarr-illustrations-falk-2022#adam-uploads\">\"Adam uploads\"</a>\n",
    "                    by Henning Falk, ©2022 NumFOCUS, is used under a CC BY 4.0 license. Modifications to this photo include cropping.\n",
    "                </small>\n",
    "            </center>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "### Software versions used for this workshop:\n",
    "\n",
    "* **bioformats2raw            0.7.0** ([install locally](https://github.com/glencoesoftware/bioformats2raw/releases/latest); requires Java)\n",
    "* **minio-client                     2020.11.17** ([install locally](https://docs.min.io/docs/minio-client-complete-guide.html))\n",
    "* **awscli                    1.29.30**\n",
    "* **napari                    0.4.18**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Setup & Sanity checks\n",
    "##\n",
    "\n",
    "YOURNAME=$(whoami)\n",
    "WORKDIR=/scratch/${YOURNAME}/session1/\n",
    "test -e ${WORKDIR} || {\n",
    "    echo Please run the first the POSIX notebook first.\n",
    "    exit 1\n",
    "}\n",
    "cd /scratch/${YOURNAME}/session1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5a. So what is the cloud?\n",
    "\n",
    "From the [BAND user guide](https://docs.google.com/document/d/1TZBUsNIciGMH_g4aFj2Lu_upISxh5TV9FBMrvNDWmc8/edit#heading=h.4tth2eqswl6h):\n",
    "\n",
    "> **Storage space**<br/>\n",
    "> Disk space is shared and limited and although data stored in your home directory and under /scratch is persistent after you terminate your running desktop, we will remove content that is older than 3 months in both your home directory and /scratch.\n",
    "Here are a few pointers:\n",
    "> * If you know you’re not going to use BAND for a while, remove your data. \n",
    "> * If you can, use external storage such as S3 buckets or file sharing services.\n",
    "> * If you have more than ~100 GB of data, put it under /scratch which has up to 20 TB in total.\n",
    "\n",
    "### Quick motivating comparison\n",
    "\n",
    "This won't work on your system because I haven't put 1GB files in each of your directories, but as an example:\n",
    "\n",
    "```bash\n",
    "$ ls -ltrad s3\n",
    "lrwxrwxrwx 1 josh_openmicroscopy users   54 Aug 25 13:37 s3 -> /nfs/home/dea88c8ad47cb989/bioimagecourse2023/session1\n",
    "\n",
    "$ ls -ltrad nfs\n",
    "lrwxrwxrwx 1 josh_openmicroscopy users   36 Aug 25 13:37 nfs -> /scratch/bioimagecourse2023/session1\n",
    "\n",
    "$ ls -ltrad local\n",
    "drwxr-xr-x 2 josh_openmicroscopy users 4096 Aug 25 13:41 local\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following script, I tested the speed of writing and then reading a 10MB file on each of these three directories:\n",
    "```bash\n",
    "set -e\n",
    "\n",
    "SZ=${SZ:-10}\n",
    "BIG=M\n",
    "SMALL=K\n",
    "SRC=urandom\n",
    "\n",
    "PV=\"pv -s ${SZ}${BIG} -N\"\n",
    "\n",
    "for x in local nfs s3;\n",
    "do\n",
    "  dd if=/dev/$SRC bs=100${SMALL} count=${SZ}0 iflag=fullblock status=none | ${PV} \"$x:w\" > ${x}/${SZ}${BIG}B\n",
    "done\n",
    "\n",
    "for x in local nfs s3;\n",
    "do\n",
    "  cat ${x}/${SZ}${BIG}B |  $PV \"$x:r\" > /dev/null\n",
    "  rm ${x}/${SZ}${BIG}B\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speeds show the differences that you need to be aware of:\n",
    "```bash\n",
    "  local:w: 9.77MiB 0:00:00 [ 139MiB/s] [========================> ] 97%            \n",
    "    nfs:w: 9.77MiB 0:00:00 [25.0MiB/s] [========================> ] 97%            \n",
    "     s3:w: 9.77MiB 0:00:00 [64.2MiB/s] [========================> ] 97%            \n",
    "  local:r: 9.77MiB 0:00:00 [1.30GiB/s] [========================> ] 97%            \n",
    "    nfs:r: 9.77MiB 0:00:00 [1.12GiB/s] [========================> ] 97%            \n",
    "     s3:r: 9.77MiB 0:00:00 [ 131MiB/s] [========================> ] 97%\n",
    "```\n",
    "Note: caching and similar can make these speeds vary *widely*.\n",
    "\n",
    "Note #2: here \"local\" is really mounted as well. 😀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b. Cloud tools\n",
    "\n",
    "There are a number of tools that are built for working with the remote filesystems directly.\n",
    "\n",
    "The first is the AWS cli from Amazon. It is likely the most complete tool, but not necessarily the easiest to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       o s3\n",
      "       o s3api\n",
      "       o s3control\n"
     ]
    }
   ],
   "source": [
    "aws help | grep s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of different types of cloud storage and there are a number of tools that you can use to access your cloud storage, but here we're going to focus on a single one `mc` (\"minio client\"). [Minio](https://min.io/) is an implementation of S3 that you can host yourself (as EMBL does with https://s3.embl.de)\n",
    "\n",
    "`mc` is provided by the minio project and is described as \"a modern alternative to UNIX commands like ls, cat, cp, mirror, diff, find etc.\" The quickstart guide can be found under https://docs.minio.io/docs/minio-client-quickstart-guide.html For our purposes we'll focus on how to use it to upload and manage data in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME:\n",
      "  mc - MinIO Client for object storage and filesystems.\n",
      "\n",
      "USAGE:\n",
      "  mc [FLAGS] COMMAND [COMMAND FLAGS | -h] [ARGUMENTS...]\n",
      "\n",
      "COMMANDS:\n",
      "  alias      manage server credentials in configuration file\n",
      "  ls         list buckets and objects\n",
      "  mb         make a bucket\n",
      "  rb         remove a bucket\n",
      "  cp         copy objects\n",
      "  mv         move objects\n",
      "  rm         remove object(s)\n",
      "  mirror     synchronize object(s) to a remote site\n",
      "  cat        display object contents\n",
      "  head       display first 'n' lines of an object\n",
      "  pipe       stream STDIN to an object\n",
      "  find       search for objects\n",
      "  sql        run sql queries on objects\n",
      "  stat       show object metadata\n",
      "  tree       list buckets and objects in a tree format\n",
      "  du         summarize disk usage recursively\n",
      "  retention  set retention for object(s)\n",
      "  legalhold  manage legal hold for object(s)\n",
      "  support    support related commands\n",
      "  license    license related commands\n",
      "  share      generate URL for temporary access to an object\n",
      "  version    manage bucket versioning\n",
      "  ilm        manage bucket lifecycle\n",
      "  encrypt    manage bucket encryption config\n",
      "  event      manage object notifications\n",
      "  watch      listen for object notification events\n",
      "  undo       undo PUT/DELETE operations\n",
      "  anonymous  manage anonymous access to buckets and objects\n",
      "  tag        manage tags for bucket and object(s)\n",
      "  diff       list differences in object name, size, and date between two buckets\n",
      "  replicate  configure server side bucket replication\n",
      "  admin      manage MinIO servers\n",
      "  update     update mc to latest release\n",
      "  ready      checks if the cluster is ready or not\n",
      "  ping       perform liveness check\n",
      "  od         measure single stream upload and download\n",
      "  \n",
      "GLOBAL FLAGS:\n",
      "  --autocompletion              install auto-completion for your shell\n",
      "  --config-dir value, -C value  path to configuration folder (default: \"/Users/jamoore/.mc\")\n",
      "  --quiet, -q                   disable progress bar display\n",
      "  --no-color                    disable color theme\n",
      "  --json                        enable JSON lines formatted output\n",
      "  --debug                       enable debug output\n",
      "  --insecure                    disable SSL certificate verification\n",
      "  --help, -h                    show help\n",
      "  --version, -v                 print the version\n",
      "  \n",
      "TIP:\n",
      "  Use 'mc --autocompletion' to enable shell autocompletion\n",
      "\n",
      "COPYRIGHT:\n",
      "  Copyright (c) 2015-0000 MinIO, Inc.\n",
      "\n",
      "LICENSE:\n",
      "  GNU AGPLv3 <https://www.gnu.org/licenses/agpl-3.0.html>\n"
     ]
    }
   ],
   "source": [
    "mc -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connections\n",
    "\n",
    "The minio project provides a safe space for you to learn about S3: https://play.minio.io:9000/minio/ Here we've used the `mc` command to find the access information:\n",
    "\n",
    " * **\"AccessKey\"** is basically a user name.\n",
    " * **\"SecretKey\"** is basically a password. \n",
    " * The URL is our **\"endpoint\"**, which differentiates it from the S3 servers provided by Amazon.\n",
    "\n",
    "You can log in to the webpage and explore what the many other users have upload at https://play.minio.io:9000/minio/\n",
    "\n",
    "The other two important concepts are:\n",
    " * **\"buckets\"** which is roughly like a shared namespace with permissions\n",
    " * and **\"keys\"** which will get to in a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[36;1mplay\n",
      "\u001b[0m\u001b[33m  URL       : https://play.min.io\n",
      "\u001b[0m\u001b[36m  AccessKey : Q3AM3UQ867SPQQA43P2F\n",
      "\u001b[0m\u001b[36m  SecretKey : zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n",
      "\u001b[0m\u001b[34m  API       : S3v4\n",
      "\u001b[0m\u001b[36m  Path      : auto\n",
      "\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mc config host list play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `mc` with a public S3 bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32mAdded `ebi` successfully.\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mc config host add ebi https://uk1s3.embassy.ebi.ac.uk \"\" \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0001A/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0013A/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0044A/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0047A/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0048A/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0050A/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0052A/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0054A/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0056B/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0062A/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0072B/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0073A/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0076A/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0083A/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0101A/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0128E/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 15:00:46 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m idr0138A/\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mc ls ebi/idr/zarr/v0.4/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the files from the IDR which have been converted into OME-NGFF:\n",
    "\n",
    "https://idr.github.io/ome-ngff-samples\n",
    "\n",
    "<img src=\"images/samples.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: configure an mc host named \"embo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mc config host list embo\n"
     ]
    }
   ],
   "source": [
    "echo mc config host list embo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5c. Our bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32m[2023-08-16 12:24:02 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m bioimagecourse2023/\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mc ls embo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32m[2023-08-31 13:10:38 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m .Trash-1566/\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2023-08-31 13:10:38 CEST]\u001b[0m\u001b[33m     0B\u001b[0m\u001b[36;1m session1/\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mc ls embo/bioimagecourse2023/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "## Half-time\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6a. Generating OME-Zarrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two basic commands are `bioformats2raw` and `raw2ometiff`. Together they provide a pipeline to scalably convert large images into OME-TIFF. The primary caveat is that they require **twice** the storage for the conversion.\n",
    "\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/blog-2019-12-converting-whole-slide-images.jpg\" style=\"height:200px\" />\n",
    "    <small><a href=\"https://forum.image.sc/t/converting-whole-slide-images-to-ome-tiff-a-new-workflow/32110/4\">Original 2019 post</a></small>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bioformats2raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/0]   0% \u001b[33m│                                     │\u001b[0m 0/1 (0:00:00 / ?) \n",
      "[0/0] 100% \u001b[33m│███████████████████████████████│\u001b[0m 1/1 (0:00:00 / 0:00:00) \u001b[1B[0/1]   0% \u001b[33m│                                     │\u001b[0m 0/1 (0:00:00 / ?) \n",
      "...TA.ome.xml: 4.83 KiB / 4.83 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.74 KiB/s 0s\u001b[0m\u001b[0m\u001b[m\u001b[32;1m\n"
     ]
    }
   ],
   "source": [
    "# Remove previous runs\n",
    "test -e a.ome.zarr && rm -rf a.ome.zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an OME-Zarr\n",
    "bioformats2raw -p a.ome.tiff a.ome.zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 6b. Publishing your data with S3 ⚠️\n",
    "\n",
    "You can then move the generated output to S3. **Note: this won't work unless you have a configured bucket that you can write to.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload it to \n",
    "mc cp -r a.ome.zarr/ embo/bioimagecourse2023/session1/${YOURNAME}/a.ome.zarr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".../0/99/0/0:  773.27 KiB / 773.27 KiB  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  132.28 KiB/s 5s\u001b[0m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\n",
      "real\t0m7.297s\n",
      "user\t0m2.158s\n",
      "sys\t0m2.216s\n"
     ]
    }
   ],
   "source": [
    "!time mc cp --recursive /tmp/trans_norm_out/0/ play/gbi2022/1885619/trans_norm.ome.zarr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using binder, you may need to access the link directly:\n",
    "\n",
    "https://hms-dbmi.github.io/vizarr/?source=https://uk1s3.embassy.ebi.ac.uk/idr/share/gbi2022/1885619/trans_norm.ome.zarr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"350\"\n",
       "            src=\"https://hms-dbmi.github.io/vizarr/?source=https://uk1s3.embassy.ebi.ac.uk/idr/share/gbi2022/1885619/trans_norm.ome.zarr/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x107e91e80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(f\"https://hms-dbmi.github.io/vizarr/?source=https://uk1s3.embassy.ebi.ac.uk/idr/share/gbi2022/1885619/trans_norm.ome.zarr/\", width=700, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This viewer is [vizarr](https://github.com/hms-dbmi/vizarr) from the [Gehlenborg lab](http://gehlenborglab.org/) at Harvard Medical School. It can be accessed at https://hms-dbmi.github.io/vizarr for example to access data from the IDR: [link](http://hms-dbmi.github.io/vizarr/v0.1?source=https%3A%2F%2Fuk1s3.embassy.ebi.ac.uk%2Fidr%2Fzarr%2Fv0.1%2F6001240.zarr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "open https://ome.github.io/ome-ngff-validator/?source=https://s3.embl.de/bioimagecourse2023/session1/${YOURNAME}/a.ome.zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using MoBIE\n",
    "\n",
    "mri.ome.zarr exported from ImageJ with the following macro:\n",
    "\n",
    "```%java\n",
    "run(\"MRI Stack\");\n",
    "Stack.setXUnit(\"mm\"); // same unit for Y and Z\n",
    "run(\"Properties...\", \"channels=1 slices=27 frames=1 pixel_width=1 pixel_height=1 voxel_depth=7\");\n",
    "run(\"Export Current Image To OME-ZARR...\", \"imagename=mri savedirectory=/tmp downsamplingmethod=Average usedefaults=true\");\n",
    "run(\"Open OME ZARR From File System...\", \"directory=/tmp/mri.ome.zarr\");\n",
    "```\n",
    "<img src=\"mri.png\" style=\"height:300px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata in a Zarr fileset is stored in (hidden) files starting with \".z\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6b. Looking into OME-Zarrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.ome.zarr/.zattrs\n",
      "a.ome.zarr/.zgroup\n",
      "a.ome.zarr/0/.zattrs\n",
      "a.ome.zarr/0/.zgroup\n",
      "a.ome.zarr/0/0/.zarray\n",
      "a.ome.zarr/0/1/.zarray\n",
      "a.ome.zarr/OME/.zattrs\n",
      "a.ome.zarr/OME/.zgroup\n"
     ]
    }
   ],
   "source": [
    "find a.ome.zarr -name \".z*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are broken up into groups (folders) or arrays (data). The `.zgroup` files are fairly simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"zarr_format\" : 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat a.ome.zarr/.zgroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `.zattrs` file contains user-supplied metadata. OME-Zarrs use these attributes to describe how an n-dimensional Zarr array should be interpreted as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> a.ome.zarr/.zattrs <==\n",
      "{\n",
      "  \"bioformats2raw.layout\" : 3\n",
      "}\n",
      "==> a.ome.zarr/0/.zattrs <==\n",
      "{\n",
      "  \"multiscales\" : [ {\n",
      "    \"metadata\" : {\n",
      "      \"method\" : \"loci.common.image.SimpleImageScaler\",\n",
      "      \"version\" : \"Bio-Formats 6.13.0\"\n",
      "    },\n",
      "    \"axes\" : [ {\n",
      "      \"name\" : \"t\",\n",
      "      \"type\" : \"time\"\n",
      "    }, {\n"
     ]
    }
   ],
   "source": [
    "head a.ome.zarr/.zattrs a.ome.zarr/0/.zattrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.zarray` files specify details about storage like compression and array dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"chunks\" : [ 1, 1, 1, 512, 512 ],\n",
      "  \"compressor\" : {\n",
      "    \"clevel\" : 5,\n",
      "    \"blocksize\" : 0,\n",
      "    \"shuffle\" : 1,\n",
      "    \"cname\" : \"lz4\",\n",
      "    \"id\" : \"blosc\"\n",
      "  },\n",
      "  \"dtype\" : \"|u1\",\n",
      "  \"fill_value\" : 0,\n",
      "  \"filters\" : null,\n",
      "  \"order\" : \"C\",\n",
      "  \"shape\" : [ 1, 1, 1, 512, 512 ],\n",
      "  \"dimension_separator\" : \"/\",\n",
      "  \"zarr_format\" : 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat a.ome.zarr/0/0/.zarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the other files in the tree are **\"chunks\"**, pieces of an array that have been written to separate files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34ma.ome.zarr\u001b[0m\n",
      "├── \u001b[01;34m0\u001b[0m\n",
      "│   ├── \u001b[01;34m0\u001b[0m\n",
      "│   │   └── \u001b[01;34m0\u001b[0m\n",
      "│   │       └── \u001b[01;34m0\u001b[0m\n",
      "│   │           └── \u001b[01;34m0\u001b[0m\n",
      "│   │               └── \u001b[01;34m0\u001b[0m\n",
      "│   │                   └── \u001b[00m0\u001b[0m\n",
      "│   └── \u001b[01;34m1\u001b[0m\n",
      "│       └── \u001b[01;34m0\u001b[0m\n",
      "│           └── \u001b[01;34m0\u001b[0m\n",
      "│               └── \u001b[01;34m0\u001b[0m\n",
      "│                   └── \u001b[01;34m0\u001b[0m\n",
      "│                       └── \u001b[00m0\u001b[0m\n",
      "└── \u001b[01;34mOME\u001b[0m\n",
      "    └── \u001b[00mMETADATA.ome.xml\u001b[0m\n",
      "\n",
      "12 directories, 3 files\n"
     ]
    }
   ],
   "source": [
    "tree a.ome.zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The levels of this hierarchy can be interpreted as:\n",
    "```\n",
    "a.ome.zarr\n",
    "└── series (Optional)\n",
    "    └── resolution-level\n",
    "        └── z-chunk-index\n",
    "            └── y-chunk-index\n",
    "                └── x-chunk-index\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6c. Other options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bioformats2raw -p a.ome.tiff a.ome.zarr -h\n",
      "\u001b[31m\u001b[1mMissing required parameter for option '--tile_height' (<tileHeight>)\u001b[21m\u001b[39m\u001b[0m\n",
      "Usage: \u001b[1m<main class>\u001b[21m\u001b[0m [\u001b[33m-p\u001b[39m\u001b[0m] [\u001b[33m--keep-memo-files\u001b[39m\u001b[0m] [\u001b[33m--no-hcs\u001b[39m\u001b[0m] [\u001b[33m--[no-]minmax\u001b[39m\u001b[0m] [\u001b[33m--[no-]\u001b[39m\u001b[0m\n",
      "             \u001b[33m       nested\u001b[39m\u001b[0m] [\u001b[33m--no-ome-meta-export\u001b[39m\u001b[0m] [\u001b[33m--no-root-group\u001b[39m\u001b[0m]\n",
      "                    [\u001b[33m--overwrite\u001b[39m\u001b[0m] [\u001b[33m--use-existing-resolutions\u001b[39m\u001b[0m] [\u001b[33m--version\u001b[39m\u001b[0m]\n",
      "                    [\u001b[33m--debug\u001b[39m\u001b[0m[=\u001b[3m<logLevel>\u001b[23m\u001b[0m]] [\u001b[33m--extra-readers\u001b[39m\u001b[0m[=\u001b[3m<extraReaders>\u001b[23m\u001b[0m[,\n",
      "                    \u001b[3m<extraReaders>\u001b[23m\u001b[0m...]]]... [\u001b[33m--options\u001b[39m\u001b[0m[=\u001b[3m<readerOptions>\u001b[23m\u001b[0m[,\n",
      "                    \u001b[3m<readerOptions>\u001b[23m\u001b[0m...]]]... [\u001b[33m-s\u001b[39m\u001b[0m[=\u001b[3m<seriesList>\u001b[23m\u001b[0m[,\n",
      "                    \u001b[3m<seriesList>\u001b[23m\u001b[0m...]]]...\n",
      "                    [\u001b[33m--additional-scale-format-string-args\u001b[39m\u001b[0m=\u001b[3m<additionalScaleForma\u001b[23m\u001b[0m\n",
      "\u001b[3m                    tCSV>\u001b[23m\u001b[0m] [\u001b[33m-c\u001b[39m\u001b[0m=\u001b[3m<compression>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--dimension-order\u001b[39m\u001b[0m=\u001b[3m<dimensionOrder>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--downsample-type\u001b[39m\u001b[0m=\u001b[3m<downsampling>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--fill-value\u001b[39m\u001b[0m=\u001b[3m<fillValue>\u001b[23m\u001b[0m] [\u001b[33m-h\u001b[39m\u001b[0m=\u001b[3m<tileHeight>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--max_cached_tiles\u001b[39m\u001b[0m=\u001b[3m<maxCachedTiles>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--max_workers\u001b[39m\u001b[0m=\u001b[3m<maxWorkers>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--memo-directory\u001b[39m\u001b[0m=\u001b[3m<memoDirectory>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--pyramid-name\u001b[39m\u001b[0m=\u001b[3m<pyramidName>\u001b[23m\u001b[0m] [\u001b[33m-r\u001b[39m\u001b[0m=\u001b[3m<resolutions>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--scale-format-string\u001b[39m\u001b[0m=\u001b[3m<scaleFormat>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--target-min-size\u001b[39m\u001b[0m=\u001b[3m<minImageSize>\u001b[23m\u001b[0m] [\u001b[33m-w\u001b[39m\u001b[0m=\u001b[3m<tileWidth>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m-z\u001b[39m\u001b[0m=\u001b[3m<chunkDepth>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--compression-properties\u001b[39m\u001b[0m=\u001b[3m<String=Object>\u001b[23m\u001b[0m]...\n",
      "                    [\u001b[33m--output-options\u001b[39m\u001b[0m=\u001b[3m<String=String>\u001b[23m\u001b[0m[\\|\u001b[3m<String=String>\u001b[23m\u001b[0m...]]...\n",
      "                    \u001b[33m<inputPath>\u001b[39m\u001b[0m \u001b[33m<outputPath>\u001b[39m\u001b[0m\n",
      "\u001b[33m \u001b[39m\u001b[0m     \u001b[33m<inputPath>\u001b[39m\u001b[0m            file to convert\n",
      "\u001b[33m \u001b[39m\u001b[0m     \u001b[33m<outputPath>\u001b[39m\u001b[0m           path to the output pyramid directory. The given\n",
      "                               path can also be a URI (containing ://) which\n",
      "                               will activate **experimental** support for\n",
      "                               Filesystems. For example, if the output path\n",
      "                               given is 's3://my-bucket/some-path' *and* you\n",
      "                               have an S3FileSystem implementation in your\n",
      "                               classpath, then all files will be written to S3.\n",
      "      \u001b[33m--additional-scale-for\u001b[39m\u001b[0m\u001b[33mmat-string-args\u001b[39m\u001b[0m=\u001b[3m<additionalScaleFormatCSV>\u001b[23m\u001b[0m\n",
      "                             Additional format string argument CSV file\n",
      "                               (without header row).  Arguments will be added\n",
      "                               to the end of the scale format string mapping\n",
      "                               the at the corresponding CSV row index.  It is\n",
      "                               expected that the CSV file contain exactly the\n",
      "                               same number of rows as the input file has series\n",
      "  \u001b[33m-c\u001b[39m\u001b[0m, \u001b[33m--compression\u001b[39m\u001b[0m=\u001b[3m<compres\u001b[23m\u001b[0m\u001b[3msion>\u001b[23m\u001b[0m\n",
      "                             Compression type for Zarr (null, zlib, blosc;\n",
      "                               default: blosc)\n",
      "      \u001b[33m--compression-properti\u001b[39m\u001b[0m\u001b[33mes\u001b[39m\u001b[0m=\u001b[3m<String=Object>\u001b[23m\u001b[0m\n",
      "                             Properties for the chosen compression (see https:\n",
      "                               //jzarr.readthedocs.io/en/latest/tutorial.\n",
      "                               html#compressors )\n",
      "      \u001b[33m--debug, --log-level\u001b[39m\u001b[0m[=\u001b[3m<logLevel>\u001b[23m\u001b[0m]\n",
      "                             Change logging level; valid values are OFF, ERROR,\n",
      "                               WARN, INFO, DEBUG, TRACE and ALL. (default: WARN)\n",
      "      \u001b[33m--dimension-order\u001b[39m\u001b[0m=\u001b[3m<dim\u001b[23m\u001b[0m\u001b[3mensionOrder>\u001b[23m\u001b[0m\n",
      "                             Override the input file dimension order in the\n",
      "                               output file [Can break compatibility with\n",
      "                               raw2ometiff] (XYZCT, XYZTC, XYCTZ, XYCZT, XYTCZ,\n",
      "                               XYTZC)\n",
      "      \u001b[33m--downsample-type\u001b[39m\u001b[0m=\u001b[3m<dow\u001b[23m\u001b[0m\u001b[3mnsampling>\u001b[23m\u001b[0m\n",
      "                             Tile downsampling algorithm (SIMPLE, GAUSSIAN,\n",
      "                               AREA, LINEAR, CUBIC, LANCZOS)\n",
      "      \u001b[33m--extra-readers\u001b[39m\u001b[0m[=\u001b[3m<extr\u001b[23m\u001b[0m\u001b[3maReaders>\u001b[23m\u001b[0m[,\u001b[3m<extraReaders>\u001b[23m\u001b[0m...]]\n",
      "                             Separate set of readers to include; (default: null)\n",
      "      \u001b[33m--fill-value\u001b[39m\u001b[0m=\u001b[3m<fillValu\u001b[23m\u001b[0m\u001b[3me>\u001b[23m\u001b[0m\n",
      "                             Default value to fill in for missing tiles (0-255)\n",
      "                               (currently .mrxs only)\n",
      "  \u001b[33m-h\u001b[39m\u001b[0m, \u001b[33m--tile_height\u001b[39m\u001b[0m=\u001b[3m<tileHei\u001b[23m\u001b[0m\u001b[3mght>\u001b[23m\u001b[0m\n",
      "                             Maximum tile height (default: 1024). This is both\n",
      "                               the chunk size (in Y) when writing Zarr and the\n",
      "                               tile size used for reading from the original\n",
      "                               data. Changing the tile size may have\n",
      "                               performance implications.\n",
      "      \u001b[33m--keep-memo-files\u001b[39m\u001b[0m      Do not delete .bfmemo files created during\n",
      "                               conversion\n",
      "      \u001b[33m--max_cached_tiles\u001b[39m\u001b[0m=\u001b[3m<ma\u001b[23m\u001b[0m\u001b[3mxCachedTiles>\u001b[23m\u001b[0m\n",
      "                             Maximum number of tiles that will be cached across\n",
      "                               all workers (default: 64)\n",
      "      \u001b[33m--max_workers\u001b[39m\u001b[0m=\u001b[3m<maxWork\u001b[23m\u001b[0m\u001b[3mers>\u001b[23m\u001b[0m\n",
      "                             Maximum number of workers (default: null)\n",
      "      \u001b[33m--memo-directory\u001b[39m\u001b[0m=\u001b[3m<memo\u001b[23m\u001b[0m\u001b[3mDirectory>\u001b[23m\u001b[0m\n",
      "                             Directory used to store .bfmemo cache files\n",
      "      \u001b[33m--no-hcs\u001b[39m\u001b[0m               Turn off HCS writing\n",
      "      \u001b[33m--[no-]minmax\u001b[39m\u001b[0m          Whether to calculate minimum and maximum pixel\n",
      "                               values. Min/max calculation can result in slower\n",
      "                               conversions. If true, min/max values are saved\n",
      "                               as OMERO rendering metadata (true by default)\n",
      "      \u001b[33m--[no-]nested\u001b[39m\u001b[0m          Whether to use '/' as the chunk path separator\n",
      "                               (true by default)\n",
      "      \u001b[33m--no-ome-meta-export\u001b[39m\u001b[0m   Turn off OME metadata exporting [Will break\n",
      "                               compatibility with raw2ometiff]\n",
      "      \u001b[33m--no-root-group\u001b[39m\u001b[0m        Turn off creation of root group and corresponding\n",
      "                               metadata [Will break compatibility with\n",
      "                               raw2ometiff]\n",
      "      \u001b[33m--options\u001b[39m\u001b[0m[=\u001b[3m<readerOpti\u001b[23m\u001b[0m\u001b[3mons>\u001b[23m\u001b[0m[,\u001b[3m<readerOptions>\u001b[23m\u001b[0m...]]\n",
      "                             Reader-specific options, in format key=value[,\n",
      "                               key2=value2]\n",
      "      \u001b[33m--output-options\u001b[39m\u001b[0m=\u001b[3m<Stri\u001b[23m\u001b[0m\u001b[3mng=String>\u001b[23m\u001b[0m[\\|\u001b[3m<String=String>\u001b[23m\u001b[0m...]\n",
      "                             |-separated list of key-value pairs to be used as\n",
      "                               an additional argument to Filesystem\n",
      "                               implementations if used. For example,\n",
      "                               --output-options=s3fs_path_style_access=true|...\n",
      "                               might be useful for connecting to minio.\n",
      "      \u001b[33m--overwrite\u001b[39m\u001b[0m            Overwrite the output directory if it exists\n",
      "      \u001b[33m--pyramid-name\u001b[39m\u001b[0m=\u001b[3m<pyrami\u001b[23m\u001b[0m\u001b[3mdName>\u001b[23m\u001b[0m\n",
      "                             Name of pyramid (default: null) [Can break\n",
      "                               compatibility with raw2ometiff]\n",
      "  \u001b[33m-r\u001b[39m\u001b[0m, \u001b[33m--resolutions\u001b[39m\u001b[0m=\u001b[3m<resolut\u001b[23m\u001b[0m\u001b[3mions>\u001b[23m\u001b[0m\n",
      "                             Number of pyramid resolutions to generate\n",
      "  \u001b[33m-s\u001b[39m\u001b[0m, \u001b[33m--series\u001b[39m\u001b[0m[=\u001b[3m<seriesList>\u001b[23m\u001b[0m[,\u001b[3m<seriesList>\u001b[23m\u001b[0m...]]\n",
      "                             Comma-separated list of series indexes to convert\n",
      "      \u001b[33m--scale-format-string\u001b[39m\u001b[0m=\u001b[3m<scaleFormat>\u001b[23m\u001b[0m\n",
      "                             Format string for scale paths; the first two\n",
      "                               arguments will always be series and resolution\n",
      "                               followed by any additional arguments brought in\n",
      "                               from `--additional-scale-format-string-args`\n",
      "                               [Can break compatibility with raw2ometiff]\n",
      "                               (default: null)\n",
      "      \u001b[33m--target-min-size\u001b[39m\u001b[0m=\u001b[3m<min\u001b[23m\u001b[0m\u001b[3mImageSize>\u001b[23m\u001b[0m\n",
      "                             Specifies the desired size for the largest XY\n",
      "                               dimension of the smallest resolution, when\n",
      "                               calculating the number of resolutions generate.\n",
      "                               If the target size cannot be matched exactly,\n",
      "                               the largest XY dimension of the smallest\n",
      "                               resolution should be smaller than the target\n",
      "                               size.\n",
      "      \u001b[33m--use-existing-resolut\u001b[39m\u001b[0m\u001b[33mions\u001b[39m\u001b[0m\n",
      "                             Use existing sub resolutions from original input\n",
      "                               format[Will break compatibility with raw2ometiff]\n",
      "  \u001b[33m-w\u001b[39m\u001b[0m, \u001b[33m--tile_width\u001b[39m\u001b[0m=\u001b[3m<tileWidt\u001b[23m\u001b[0m\u001b[3mh>\u001b[23m\u001b[0m\n",
      "                             Maximum tile width (default: 1024). This is both\n",
      "                               the chunk size (in X) when writing Zarr and the\n",
      "                               tile size used for reading from the original\n",
      "                               data. Changing the tile size may have\n",
      "                               performance implications.\n",
      "  \u001b[33m-z\u001b[39m\u001b[0m, \u001b[33m--chunk_depth\u001b[39m\u001b[0m=\u001b[3m<chunkDe\u001b[23m\u001b[0m\u001b[3mpth>\u001b[23m\u001b[0m\n",
      "                             Maximum chunk depth to read (default: 1)\n",
      "  \u001b[33m-p\u001b[39m\u001b[0m, \u001b[33m--progress\u001b[39m\u001b[0m             Print progress bars during conversion\n",
      "      \u001b[33m--version\u001b[39m\u001b[0m              Print version information and exit\n"
     ]
    }
   ],
   "source": [
    "!bioformats2raw -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ome_zarr info a.ome.zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extras (time-permitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 A larger example (idr0062)\n",
    "\n",
    "If you are using binder, you may need to access the link directly:\n",
    "\n",
    "https://hms-dbmi.github.io/vizarr/?source=https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.1/6001240.zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"350\"\n",
       "            src=\"http://hms-dbmi.github.io/vizarr/v0.1?source=https%3A%2F%2Fuk1s3.embassy.ebi.ac.uk%2Fidr%2Fzarr%2Fv0.1%2F6001240.zarr\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x107e962b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"http://hms-dbmi.github.io/vizarr/v0.1?source=https%3A%2F%2Fuk1s3.embassy.ebi.ac.uk%2Fidr%2Fzarr%2Fv0.1%2F6001240.zarr\", width=700, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Renaming\n",
    "\n",
    "Another important distinction to filesystems is that though it looks like hello is in a directory, you should really think of the entire string after the bucket just as a \"key\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".../0/99/0/0:  773.27 KiB / 773.27 KiB  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  144.06 KiB/s 5s\u001b[0m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "!mc mv --recursive uk1/idr/share/gbi2022/1885619/trans_norm.ome.zarr/ uk1/idr/share/gbi2022/1885619/renamed.ome.zarr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Other resources\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a href=\"https://downloads.openmicroscopy.org/presentations/2020/Dundee/Workshops/NGFF/zarr_diagram/\">\n",
    "<img src=\"images/resources-1.png\" alt=\"Screenshot of the Zarr diagram from OME2020\" style=\"height:200px\"/>\n",
    "            </a>\n",
    "        </td>\n",
    "        <td>\n",
    "<a href=\"https://downloads.openmicroscopy.org/presentations/2020/Dundee/Workshops/NGFF/zarr_diagram/\">Diagram for how data moves</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "      <a href=\"https://blog.openmicroscopy.org/file-formats/community/2020/11/04/zarr-data/\">      \n",
    "<img src=\"images/resources-2.png\" alt=\"Screenshot of the Zarr diagram from OME2020\" style=\"height:200px\"/>\n",
    "            </a>\n",
    "        </td>\n",
    "        <td>\n",
    "<a href=\"https://blog.openmicroscopy.org/file-formats/community/2020/11/04/zarr-data/\">Blog post for an easy way to publish OME-Zarr files</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Trying more with minio's play\n",
    "\n",
    "Note, however, that play buckets get deleted every 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32;1mBucket created successfully `play/gbi2022`.\u001b[0m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!mc mb --ignore-existing play/gbi2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32;1mAccess permission for `play/gbi2022` is set to `public`\u001b[0m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!mc policy set public play/gbi2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".../0/99/0/0:  773.27 KiB / 773.27 KiB  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  134.17 KiB/s 5s\u001b[0m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "!mc cp -r /tmp/trans_norm_out/0/ play/gbi2022/trans_norm.ome.zarr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run: `napari https://play.minio.io/gbi2022/trans_norm.ome.zarr`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time permitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/Users/jamoore/micromamba/envs/embo/share/bftools-7.0.0-0/bioformats_package.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/System/Volumes/Data/scratch/bioimagecourse2023/session1/OMEZarrReader-0.3.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [ch.qos.logback.classic.util.ContextSelectorStaticBinder]\n",
      "Checking file format [Zarr]\n",
      "Initializing reader\n",
      "ZarrReader initializing mri.ome.zarr/.zattrs\n",
      "Exception in thread \"main\" java.lang.IllegalArgumentException: Compressor id:'gzip' not supported.\n",
      "\tat com.bc.zarr.CompressorFactory.create(CompressorFactory.java:123)\n",
      "\tat com.bc.zarr.CompressorFactory.create(CompressorFactory.java:87)\n",
      "\tat com.bc.zarr.ZarrHeader$ZarrHeaderDeSerializer.deserialize(ZarrHeader.java:197)\n",
      "\tat com.bc.zarr.ZarrHeader$ZarrHeaderDeSerializer.deserialize(ZarrHeader.java:169)\n",
      "\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n",
      "\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4730)\n",
      "\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3690)\n",
      "\tat com.bc.zarr.ZarrUtils.fromJson(ZarrUtils.java:113)\n",
      "\tat com.bc.zarr.ZarrArray.open(ZarrArray.java:109)\n",
      "\tat com.bc.zarr.ZarrArray.open(ZarrArray.java:99)\n",
      "\tat com.bc.zarr.ZarrArray.open(ZarrArray.java:95)\n",
      "\tat com.bc.zarr.ZarrArray.open(ZarrArray.java:91)\n",
      "\tat loci.formats.services.JZarrServiceImpl.getArrayAttr(JZarrServiceImpl.java:116)\n",
      "\tat loci.formats.in.ZarrReader.initFile(ZarrReader.java:206)\n",
      "\tat loci.formats.FormatReader.setId(FormatReader.java:1466)\n",
      "\tat loci.formats.ImageReader.setId(ImageReader.java:863)\n",
      "\tat loci.formats.ReaderWrapper.setId(ReaderWrapper.java:660)\n",
      "\tat loci.formats.tools.ImageInfo.testRead(ImageInfo.java:1043)\n",
      "\tat loci.formats.tools.ImageInfo.main(ImageInfo.java:1129)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cd /scratch/bioimagecourse2023/session1/EMBO-Practical-Course-2023\n",
    "export BF_CP=/scratch/bioimagecourse2023/session1/OMEZarrReader-0.3.1-jar-with-dependencies.jar\n",
    "showinf -nopix mri.ome.zarr/.zattrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Take homes\n",
    "\n",
    "<br/>\n",
    "<big><big>\n",
    "    <ol>\n",
    "        <li>\n",
    "The simplicity & transparency of Zarr files makes them ideal for exploration & the cloud. \n",
    "        </li>\n",
    "         <br/>\n",
    "        <li>\n",
    "The primary downside is that working with many small files can introduce bottlenecks for uploading (& even deleting).\n",
    "        </li>\n",
    "        <br/>\n",
    "        <li>\n",
    "Working with S3 is very different from a file system, fewer (GUI) tools exist, and each S3 implementation may be slightly different.\n",
    "        </li>\n",
    "        <br/>\n",
    "        <li>\n",
    "The benefits in sharing potential (and in some cases cost-savings) can be significant, especially if there's an enabled ecosystem that works for you.\n",
    "        </li>\n",
    "    </ol>\n",
    "</big></big>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## License\n",
    "Copyright (C) 2023 German BioImaging. All Rights Reserved.\n",
    "This program is free software; you can redistribute it and/or modify it\n",
    "under the terms of the GNU General Public License as published by the\n",
    "Free Software Foundation; either version 2 of the License, or\n",
    "(at your option) any later version.\n",
    "This program is distributed in the hope that it will be useful, but\n",
    "WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n",
    "or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for\n",
    "more details. You should have received a copy of the GNU General\n",
    "Public License along with this program; if not, write to the\n",
    "Free Software Foundation,\n",
    "Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
